{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "from pomegranate import *\n",
    "from keras_performance_metrics import *\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "from threading import Thread\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from MDLP import MDLP_Discretizer\n",
    "import entropy_based_binning as ebb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Functions\n",
    "def multiclass_roc_auc_score(truth, pred):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_classifiers(xtrain, xtest, clf):\n",
    "    wc_class_reports, wc_confmatrices, wc_auc_scores, wc_recall_scores, wc_precision_scores, wc_f1_scores, wc_accuracy_scores =[],[],[],[],[],[],[]\n",
    "    ytrain = xtrain['class']\n",
    "    xtrain = xtrain.drop(columns = 'class')\n",
    "    trainarr = np.array(xtrain)\n",
    "    ytest =  xtest['class'] \n",
    "    xtest = xtest.drop(columns = 'class')\n",
    "    testarr = np.array(xtest)\n",
    "    clf.fit(trainarr,ytrain)\n",
    "    wc_predicted = clf.predict(testarr)\n",
    "    wc_predicted = np.array( wc_predicted, dtype = \"int64\")\n",
    "    y_true = np.array(ytest, dtype = \"int64\")\n",
    "\n",
    "    print(\"Model Evaluation\")\n",
    "    _precision, _recall, _fscore, _support = precision_recall_fscore_support(y_true, wc_predicted)\n",
    "    _accuracy_score = balanced_accuracy_score(y_true, wc_predicted)\n",
    "    _auc_score = multiclass_roc_auc_score(y_true, wc_predicted)\n",
    "    _conf_matrix = confusion_matrix(y_true, wc_predicted)\n",
    "    print( classification_report(y_true, wc_predicted))\n",
    "   \n",
    "    \n",
    "    print(\"Accuracy exact: %.3f\" % (_accuracy_score))\n",
    "    print(\"AUC: %.3f\\n\" % (_auc_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(iter, generation_scores)? (<ipython-input-20-4ecd07ff0335>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-4ecd07ff0335>\"\u001b[1;36m, line \u001b[1;32m132\u001b[0m\n\u001b[1;33m    print iter, generation_scores\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(iter, generation_scores)?\n"
     ]
    }
   ],
   "source": [
    "def genetic_feature_selection(train_x, train_y, task, model, folds, eval_metric, categorical_features = [], n_classes = 2, sparse = False, iterations = 100, generation_size = 20, generation_best_ratio = 10, mutation_prob = 0.05, stopping_rounds = -1, epochs = None, average_epochs = None, missing = np.nan, verbose = False):\n",
    "    \"\"\"genetic algorithm for features selection\n",
    "    \n",
    "    all features are encoded  as binary vector\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_x : pandas.DataDrame or numpy.ndarray\n",
    "        train dataset\n",
    "    train_y : np.ndarray\n",
    "        target\n",
    "    task : string, 'regression' or 'binary_classification' or 'multiclass_classification'\n",
    "        task to solve\n",
    "    model : Model\n",
    "        Model  instance\n",
    "    folds : list of pairs of lists\n",
    "        indices of train and validation folds\n",
    "        folds[i][0] - train indices in i-th train-val split\n",
    "        folds[i][1] - validation indices in i-th train-val split\n",
    "    eval_metric : string, possible variants: 'mse', rmse', 'auc', 'logloss', 'mlogloss', 'error', 'merror' \n",
    "        eval_metric for model\n",
    "    categorical_features : list of strings or lists of integers, optional\n",
    "        column names (if train is Pandas DataFrame) or column indices (if train is Numpy array) of categorical features\n",
    "        [] by default\n",
    "    n_classes : integer, optional\n",
    "        number of classes in case of classification task\n",
    "        2 by default\n",
    "    sparse : boolean, optional\n",
    "        whether train is sparse Scipy matrix\n",
    "        False by default\n",
    "    iterations : integer, optional\n",
    "        number of iterations in genetic algorithm\n",
    "        100 by default\n",
    "    generation_size : integer, optional\n",
    "        number of objects in one generation\n",
    "        20 by default\n",
    "    generation_best_ratio : integer, optional\n",
    "        number of best objects to survive to next generation\n",
    "        10 by default\n",
    "    generation_best_ratio : float, optional\n",
    "        mutation probability\n",
    "        0.05 by default\n",
    "    stopping rounds : integer, optional\n",
    "        number of early stopping rounds (or epochs for neral nets) in CV evaluations, -1 means for fixed number of rounds or epochs\n",
    "        -1 by default\n",
    "    epochs : integer, optional\n",
    "        number of epochs in case of neural network model\n",
    "        10 by default\n",
    "    average_epochs : integer, optional\n",
    "        number of last epochs, predictions in which are averaged, in case of neural network model\n",
    "        -1 by default\n",
    "    missing : integer or np.nan\n",
    "        missing values for xgboost models\n",
    "        np.nan by default\n",
    "    verbose : , optional\n",
    "        whether to print running info\n",
    "        False by default\n",
    "    Returns \n",
    "    -------\n",
    "    list of best features, best CV score  (CV score with selected features)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    n_features = train_x.shape[1]\n",
    "\n",
    "    if isinstance(train_x, pd.DataFrame):\n",
    "        train_values = train_x.values\n",
    "        features_list = train_x.columns.values\n",
    "    else:\n",
    "        features_list = np.arange(n_features)\n",
    "        train_values = train_x\n",
    "\n",
    "    def score_features(features_sample):\n",
    "            \n",
    "        features_ind = np.where(features_sample == 1)[0]\n",
    "\n",
    "        if model.type == 'xgboost':\n",
    "            return cross_validation.CV_score_xgb(train_values[:, features_ind], train_y, model.params, eval_metric, folds, sparse = sparse, stopping_rounds = stopping_rounds, missing = missing, verbose = False)\n",
    "        \n",
    "        elif model.type == 'lightgbm':\n",
    "            return cross_validation.CV_score_lgbm(train_values[:, features_ind], train_y, model.params, categorical_features, eval_metric, folds, stopping_rounds = stopping_rounds, verbose = False)\n",
    "\n",
    "        elif model.type == 'keras':\n",
    "            return cross_validation.CV_score_keras(train_values[:, features_ind], train_y, task, model.params, eval_metric, folds, n_classes = n_classes, stopping_rounds = stopping_rounds, epochs = epochs, average_epochs = average_epochs, verbose = False)\n",
    "\n",
    "        elif model.type == 'sklearn':\n",
    "            return cross_validation.CV_score_sklearn(train_values[:, features_ind], train_y, model, eval_metric, folds, verbose = False)\n",
    "\n",
    "    generation = np.zeros((generation_size, n_features), dtype = np.int16)\n",
    "    generation_scores = np.zeros((generation_size, ), dtype = np.float32)\n",
    "\n",
    "    def random_sample():\n",
    "        sample = np.zeros((n_features, ), dtype = np.int16)\n",
    "        for i in range(n_features):\n",
    "            if np.random.uniform(0, 1) < 0.5:\n",
    "                sample[i] = 1\n",
    "        return sample\n",
    "\n",
    "    def crossover(parent_a, parent_b):\n",
    "        child = np.copy(parent_a)\n",
    "        for i in range(n_features):\n",
    "            if np.random.uniform(0, 1) < 0.5:\n",
    "                child[i] = parent_b[i]\n",
    "        return child\n",
    "\n",
    "    def mutation(sample):\n",
    "        mutated_sample = np.copy(sample)\n",
    "        for i in range(n_features):\n",
    "            if np.random.uniform(0, 1) < mutation_prob:\n",
    "                mutated_sample[i] ^= 1\n",
    "        return mutated_sample\n",
    "\n",
    "    def sort_generation(generation, generation_scores):\n",
    "        \n",
    "        sort_ind = np.argsort(generation_scores)\n",
    "        if eval_metric == 'auc':\n",
    "            sort_ind = sort_ind[::-1]\n",
    "\n",
    "        generation = generation[sort_ind]\n",
    "        generation_scores = generation_scores[sort_ind]\n",
    "\n",
    "        return generation, generation_scores\n",
    "\n",
    "    for i in range(generation_size):\n",
    "        generation[i] = random_sample()\n",
    "        generation_scores[i] = score_features(generation[i])\n",
    "\n",
    "    for iter in range(iterations):\n",
    "\n",
    "        generation, generation_scores = sort_generation(generation, generation_scores)\n",
    "        if verbose:\n",
    "            print iter, generation_scores\n",
    "            print 'cur best: ', features_list[np.where(generation[0] == 1)[0]]\n",
    "\n",
    "        for i in range(generation_best_ratio, generation_size, 1):\n",
    "            parent_a = generation[np.random.randint(0, generation_best_ratio)]\n",
    "            parent_b = generation[np.random.randint(0, generation_best_ratio)]\n",
    "            child = crossover(parent_a, parent_b)\n",
    "            mutated_child = mutation(child)\n",
    "            generation[i] = np.copy(mutated_child)\n",
    "            generation_scores[i] = score_features(generation[i])\n",
    "            if verbose:\n",
    "                print i, generation_scores[i]\n",
    "\n",
    "    sort_generation(generation, generation_scores)\n",
    "    best_features, best_score = generation[0], generation_scores[0]     \n",
    "    best_features = features_list[np.where(best_features == 1)[0]]\n",
    "    \n",
    "    if verbose:\n",
    "        print 'best features set: ', best_features\n",
    "        print 'best score: ', best_score\n",
    "\n",
    "    return best_features, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sf_total_number_of_sentences  sf_total_number_of_words  \\\n",
      "0                            18                       224   \n",
      "1                            48                       836   \n",
      "2                            29                       435   \n",
      "3                            50                       534   \n",
      "4                             7                        90   \n",
      "\n",
      "   sf_total_number_of_characters  sf_total_number_of_begin_upper  \\\n",
      "0                           1100                              47   \n",
      "1                           4448                             208   \n",
      "2                           2073                             104   \n",
      "3                           2135                             116   \n",
      "4                            448                              30   \n",
      "\n",
      "   sf_total_number_of_begin_lower  sf_total_number_of_all_caps  \\\n",
      "0                             183                            4   \n",
      "1                             797                           21   \n",
      "2                             395                           10   \n",
      "3                             504                           12   \n",
      "4                              57                            4   \n",
      "\n",
      "   sf_total_number_of_stopwords  sf_total_number_of_lines  \\\n",
      "0                            78                        15   \n",
      "1                           370                        43   \n",
      "2                           197                        39   \n",
      "3                           251                        51   \n",
      "4                            32                         9   \n",
      "\n",
      "   sf_ratio_alphabetic  sf_ratio_uppercase  ...    vr_happax_legomena  \\\n",
      "0             1.135455            0.058182  ...                   139   \n",
      "1             1.195818            0.064973  ...                   366   \n",
      "2             1.174626            0.064641  ...                   201   \n",
      "3             1.303513            0.060890  ...                   226   \n",
      "4             1.095982            0.133929  ...                    50   \n",
      "\n",
      "   vr_happax_dislegomena    vr_ttr  vr_brunets_w  vr_honore_r  vr_sichel_s  \\\n",
      "0                     26  0.584507     10.816421  1371.204003     0.102113   \n",
      "1                    140  0.414508     12.001599  1280.415784     0.133851   \n",
      "2                     98  0.457711     11.896699  1221.631668     0.144279   \n",
      "3                     94  0.413605     12.323159  1168.892727     0.129252   \n",
      "4                     24  0.582609     10.292704  1160.994031     0.156522   \n",
      "\n",
      "   vr_yules_k  s_polarity  s_subjectivity  class  \n",
      "0   12.149912   -0.034001        0.269783      0  \n",
      "1   11.351991   -0.030541        0.562335      0  \n",
      "2    9.234574    0.035069        0.505279      0  \n",
      "3    7.016627    0.221190        0.547460      0  \n",
      "4    8.942231   -0.004167        0.444444      0  \n",
      "\n",
      "[5 rows x 187 columns]\n",
      "[array([   1.,    7.,   20., 1633.]), array([    4.,   128.,   362., 25496.]), array([    11.,    614.,   1774., 200726.]), array([    0.,    31.,    74., 11343.]), array([    0.,   102.,   344., 28407.]), array([    0.,     2.,     8., 10563.]), array([    0.,    48.,   161., 13966.]), array([   1.,   11.,   27., 8345.]), array([0.0245835 , 1.15766181, 1.24113887, 2.91666667]), array([0.        , 0.05254237, 0.07836183, 1.        ]), array([0.        , 0.00516774, 0.01625321, 0.66127274]), array([   0.31977508,    4.31731674,    4.92689837, 2362.326233  ]), array([   2.97810219,   14.71428571,   19.33333333, 6073.        ]), array([    4.94890511,    69.25      ,    95.83333333, 18755.5       ]), array([0.        , 0.18701265, 0.26386782, 0.95238095]), array([0.        , 0.00971178, 0.02648809, 0.95652174]), array([0.        , 0.77419355, 0.97337963, 2.33333333]), array([0.00260417, 0.3396482 , 0.39274693, 1.17346939]), array([  0.,   5.,  22., 743.]), array([  0.,   1.,   8., 189.]), array([  0.,   1.,   6., 145.]), array([  0.,   2.,   6., 245.]), array([  0.,   2., 107.]), array([ 0.,  1., 15.]), array([ 0.,  1., 34.]), array([ 0.,  1., 12.]), array([0., 7.]), array([ 0.,  1., 33.]), array([ 0.,  3., 41.]), array([ 0.,  2., 38.]), array([ 0., 16.]), array([0., 4.]), array([0., 3.]), array([0., 1., 8.]), array([ 0.,  1., 26.]), array([ 0., 16.]), array([ 0.,  1., 27.]), array([ 0., 12.]), array([ 0.,  1., 18.]), array([0., 6.]), array([  0.,   1., 100.]), array([ 0., 18.]), array([ 0., 27.]), array([ 0., 11.]), array([ 0., 13.]), array([ 0., 10.]), array([ 0., 14.]), array([ 0., 25.]), array([ 0.,  3., 48.]), array([ 0., 20.]), array([0., 9.]), array([0., 6.]), array([ 0.,  1., 35.]), array([ 0., 16.]), array([ 0., 21.]), array([ 0., 13.]), array([ 0., 12.]), array([ 0., 11.]), array([ 0., 13.]), array([ 0., 15.]), array([ 0.,  1., 34.]), array([ 0.,  1., 34.]), array([ 0.,  2.,  7., 63.]), array([ 0., 17.]), array([ 0.,  1., 30.]), array([ 0., 16.]), array([ 0., 16.]), array([ 0., 21.]), array([ 0., 27.]), array([ 0.,  3.,  7., 87.]), array([ 0.,  2.,  7., 89.]), array([ 0.,  3.,  9., 98.]), array([ 0.,  2., 49.]), array([ 0.,  1., 24.]), array([ 0.,  2.,  5., 51.]), array([ 0.,  2., 28.]), array([ 0., 22.]), array([ 0., 27.]), array([ 0., 22.]), array([ 0.,  2., 20.]), array([ 0.,  3., 96.]), array([ 0., 14.]), array([ 0.,  1., 39.]), array([  0.,   2.,   7., 243.]), array([ 0.,  1.,  4., 81.]), array([ 0.,  1.,  3., 47.]), array([ 0.,  1.,  3., 86.]), array([ 0.,  1., 16.]), array([ 0.,  1., 11.]), array([ 0., 17.]), array([  0.,  53., 119., 895.]), array([ 0.,  2., 59.]), array([ 0.,  1.,  2., 76.]), array([  0.,   7.,  19., 382.]), array([  0.,   3.,  12., 578.]), array([  0.,   8.,  23., 583.]), array([-5.  ,  0.  ,  0.75,  5.  ]), array([   0., 5747.]), array([  0., 258.]), array([   0., 4626.]), array([   0.,    1.,    2., 4100.]), array([   0.,    1.,    2., 4102.]), array([   0.,    5.,   21., 8808.]), array([   0.,    7.,   20., 1654.]), array([    0.,     1.,     4., 10715.]), array([   0., 1388.]), array([   0.,    4.,   14., 6371.]), array([    0.,     2.,     9., 10105.]), array([   0.,   13.,   42., 3280.]), array([  0., 103.]), array([   0., 2399.]), array([   0.,   17.,   53., 4058.]), array([   0.,   10.,   32., 2651.]), array([  0.,   1., 189.]), array([  0.,   1., 130.]), array([  0.,   1.,   4., 670.]), array([    0.,    22.,    68., 10273.]), array([    0.,    23.,    56., 13867.]), array([  0.,   1., 197.]), array([   0.,    7.,   25., 1774.]), array([  0., 106.]), array([  0., 446.]), array([   0.,    3.,   12., 2129.]), array([  0.,   2.,   6., 717.]), array([   0.,    4.,   16., 1742.]), array([ 0.,  1., 81.]), array([ 0., 35.]), array([  0.,   1., 170.]), array([ 0., 49.]), array([  0.,   3.,  12., 990.]), array([ 0., 83.]), array([   0.,    4.,   15., 1509.]), array([   0.,    2.,   11., 1762.]), array([  0.,   2.,   9., 780.]), array([  0.,   2.,   9., 752.]), array([   0.,    3.,    9., 1225.]), array([  0.,   4.,  12., 993.]), array([  0.,   2., 204.]), array([  0.,   2., 302.]), array([ 0., 31.]), array([  0.,   2., 219.]), array([  0.,   1.,   4., 670.]), array([   0.,    5.,   21., 2446.]), array([   0.,   10.,   31., 2838.]), array([  0., 772.]), array([  0.,   1., 345.]), array([  0.,   1., 942.]), array([  0.,   1., 322.]), array([   0., 4833.]), array([   0., 2417.]), array([    4.,   218.,   669., 49211.]), array([-9038.93,    55.13,    68.36,   158.95]), array([ 0. , 10. , 12.3, 93.3]), array([  -7.6,    7.9,   10.6, 1280. ]), array([  -8.51,   11.66,   14.09, 4005.49]), array([  -4.7,   11.1,   14.4, 3257.1]), array([  0.19,   7.8 ,   8.63, 152.47]), array([   0.,   34.,   98., 4311.]), array([  0. ,   6.5,  10.3, 107.5]), array([   3.52      ,   17.34429907,   20.07595331, 1230.613361  ]), array([   0.,   78.,  171., 3492.]), array([   0.,   26.,   68., 2892.]), array([0.01038339, 0.45723684, 0.59444444, 1.        ]), array([ 2.99441588, 10.49048941, 11.87878113, 78.95779636]), array([  287.8231366,  1188.086028 ,  1315.00887  , 13825.86065  ]), array([0.        , 0.12307692, 0.14201183, 0.5       ]), array([  0.        ,   8.93289265,  14.67038151, 768.        ]), array([-1.        ,  0.05277778,  0.1383214 ,  1.        ]), array([0.        , 0.38064394, 0.46913723, 1.        ])]\n",
      "   Unnamed: 0  sf_total_number_of_sentences  sf_total_number_of_words  \\\n",
      "0           0                             3                         2   \n",
      "1           1                             4                         4   \n",
      "2           2                             3                         3   \n",
      "3           3                             4                         3   \n",
      "4           4                             1                         1   \n",
      "\n",
      "   sf_total_number_of_characters  sf_total_number_of_begin_upper  \\\n",
      "0                              2                               2   \n",
      "1                              4                               4   \n",
      "2                              3                               3   \n",
      "3                              3                               4   \n",
      "4                              1                               1   \n",
      "\n",
      "   sf_total_number_of_begin_lower  sf_total_number_of_all_caps  \\\n",
      "0                               2                            2   \n",
      "1                               4                            4   \n",
      "2                               3                            3   \n",
      "3                               3                            3   \n",
      "4                               1                            2   \n",
      "\n",
      "   sf_total_number_of_stopwords  sf_total_number_of_lines  \\\n",
      "0                             2                         2   \n",
      "1                             4                         4   \n",
      "2                             3                         4   \n",
      "3                             4                         4   \n",
      "4                             1                         1   \n",
      "\n",
      "   sf_ratio_alphabetic  ...    vr_happax_legomena  vr_happax_dislegomena  \\\n",
      "0                    1  ...                     2                      1   \n",
      "1                    2  ...                     4                      4   \n",
      "2                    1  ...                     3                      4   \n",
      "3                    4  ...                     3                      3   \n",
      "4                    0  ...                     0                      1   \n",
      "\n",
      "   vr_ttr  vr_brunets_w  vr_honore_r  vr_sichel_s  vr_yules_k  s_polarity  \\\n",
      "0       3             1            3            0           2           0   \n",
      "1       1             3            2            2           2           0   \n",
      "2       1             3            2            3           1           1   \n",
      "3       1             4            1            2           1           4   \n",
      "4       3             1            1            4           1           0   \n",
      "\n",
      "   s_subjectivity  class  \n",
      "0               0      0  \n",
      "1               4      0  \n",
      "2               4      0  \n",
      "3               4      0  \n",
      "4               2      0  \n",
      "\n",
      "[5 rows x 188 columns]\n"
     ]
    }
   ],
   "source": [
    "#Discretization into smaller number of categories\n",
    "#df = top_20_features_df\n",
    "binned_data = []\n",
    "discrete_data = []\n",
    "df = pd.read_csv(\"datafiles/content_features2.csv\")\n",
    "\n",
    "for val in range(0,len(df.columns)):\n",
    "    if(df.iloc[:,val].nunique() > 10):#only applied to discrete data with more than 5 values and continuous data\n",
    "        [df.iloc[:,val], bins] = pd.qcut(df.iloc[:,val], 10, duplicates = 'drop', retbins = True)\n",
    "        binned_data.append(bins)# store the bins used for each column (not the labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 2 4 3 2 4 4 4 4 4 4 4 4 4 4 4 3 4 2 "
     ]
    }
   ],
   "source": [
    "#No of values of each variable\n",
    "dfentr = pd.read_csv(\"datafiles/sample_featuresENTRbins.csv\")\n",
    "for val in range(0,len(dfentr.columns)):\n",
    "   print(dfentr.iloc[:,val].nunique(), end =' ')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#top_20_features_discdf = pd.read_csv('datafiles/top_features.csv')\n",
    "df_class0 = top_20_features_discdf.loc[top_20_features_discdf['class'] == 0]\n",
    "df_class1 = top_20_features_discdf.loc[top_20_features_discdf['class'] == 1]\n",
    "df0 = df_class0.sample(n = 5000)\n",
    "df1 = df_class1.sample(n = 5000)\n",
    "df2 = pd.concat([df0, df1])\n",
    "df2.to_csv('datafiles/sample_featuresENTRbins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.60 missing values.\n",
      "\n",
      "21 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.98.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0117262\tvalid_0's auc: 0.999774\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0114541\tvalid_0's auc: 0.99977\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0106496\tvalid_0's auc: 0.999829\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0117003\tvalid_0's auc: 0.999753\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0115068\tvalid_0's auc: 0.99976\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0114934\tvalid_0's auc: 0.999802\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's binary_logloss: 0.0113798\tvalid_0's auc: 0.999787\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0123092\tvalid_0's auc: 0.999763\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0112578\tvalid_0's auc: 0.99977\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0119602\tvalid_0's auc: 0.999772\n",
      "\n",
      "22 features with zero importance after one-hot encoding.\n",
      "\n",
      "155 features required for cumulative importance of 0.99 after one hot encoding.\n",
      "32 features do not contribute to cumulative importance of 0.99.\n",
      "\n",
      "33 total features out of 187 identified for removal after one-hot encoding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_selector import FeatureSelector\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)\n",
    "discdf =  dfentr\n",
    "train_labels = discdf['class']\n",
    "train = discdf.drop(columns = ['class'])\n",
    "fs = FeatureSelector(data = train, labels = train_labels)\n",
    "fs.identify_all(selection_params = {'missing_threshold': 0.6, 'correlation_threshold': 0.98, \n",
    "                                    'task': 'classification', 'eval_metric': 'auc', \n",
    "                                     'cumulative_importance': 0.99})\n",
    "top_20_features_df = discdf[fs.feature_importances.iloc[:20][\"feature\"]]\n",
    "top_20_features_discdf = pd.concat([top_20_features_df, train_labels], axis = 1)\n",
    "\n",
    "top_20_features_discdf.to_csv('datafiles/top_features2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = discdf['class']\n",
    "train_x = discdf.drop(columns = ['class'])\n",
    "genetic_feature_selection(train_x, train_y, binary_classification, model, folds, eval_metric, categorical_features = [], n_classes = 2, sparse = False, iterations = 100, generation_size = 20, generation_best_ratio = 10, mutation_prob = 0.05, stopping_rounds = -1, epochs = None, average_epochs = None, missing = np.nan, verbose = False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genetic_feature_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-675923be1c07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mbn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianNetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'greedy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_parents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mgenetic_feature_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_classification'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_best_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutation_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Inference process\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'genetic_feature_selection' is not defined"
     ]
    }
   ],
   "source": [
    "from pomegranate import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 11\n",
    "\n",
    "df3 = pd.read_csv('datafiles/sample_featuresENTRbins.csv')\n",
    "#df3 = df2.reset_index(drop=True, inplace = True)\n",
    "\n",
    "wc_class_reports, wc_confmatrices, wc_auc_scores, wc_recall_scores, wc_precision_scores, wc_f1_scores, wc_accuracy_scores =[],[],[],[],[],[],[]\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False, random_state = seed)\n",
    "folds = []\n",
    "for train_index, test_index in kfold.split(df3,df3['class']):\n",
    "\n",
    "    xtrain = df3.loc[train_index,:]\n",
    "    xtest = df3.loc[test_index,:]\n",
    "    ytrain = xtrain['class']\n",
    "    ytest = xtest['class']\n",
    "   \n",
    "\n",
    "    xtest['class']= np.nan\n",
    "    trainarr = np.array(xtrain)\n",
    "    testarr = np.array(xtest)\n",
    "  \n",
    "    bn_model = BayesianNetwork.from_samples(trainarr, algorithm='greedy',max_parents = 4, n_jobs=-1)\n",
    "    genetic_feature_selection(xtrain, ytrain, bn_model, folds, task = 'binary_classification',eval_metric = 'auc', categorical_features = list(xtrain.columns) , n_classes = 2, sparse = False, iterations = 100, generation_size = 20, generation_best_ratio = 10, mutation_prob = 0.05, stopping_rounds = -1)\n",
    "    print(\"Inference process\\n\")\n",
    "    \n",
    "    #, folds), eval_metric = 'auc', categorical_features = list(xtrain.columns) , n_classes = 2, sparse = False, iterations = 100, generation_size = 20, generation_best_ratio = 10, mutation_prob = 0.05, stopping_rounds = -1)\n",
    "    print(\"Inference process\\n\")\n",
    "    print(bn_model.structure)\n",
    "    bn_model.fit(trainarr, n_jobs=-1)   \n",
    "       # xtest['class'] = np.nan\n",
    "    wc_predicted = model.predict(testarr, n_jobs=-1)\n",
    "    wc_predicted = np.array( wc_predicted, dtype = \"int64\")\n",
    "\n",
    "    wc_predicted = wc_predicted[:,len(xtrain.columns)-1]\n",
    "    wc_predicted = wc_predicted.reshape(-1)\n",
    "    y_true = np.array(classval, dtype = \"int64\")\n",
    "    y_true = y_true.reshape(-1)\n",
    "    _precision, _recall, _fscore, _support = precision_recall_fscore_support(y_true, wc_predicted)\n",
    "    _accuracy_score = accuracy_score(y_true, wc_predicted)\n",
    "    _auc_score =roc_auc_score(y_true, wc_predicted)\n",
    "    _conf_matrix = confusion_matrix(y_true, wc_predicted)\n",
    "    _class_report = classification_report(y_true, wc_predicted)\n",
    "    wc_accuracy_scores.append(_accuracy_score)\n",
    "    wc_f1_scores.append(_fscore)\n",
    "    wc_precision_scores.append(_precision)\n",
    "    wc_recall_scores.append(_recall)\n",
    "    wc_auc_scores.append(_auc_score)\n",
    "    wc_confmatrices.append(_conf_matrix)\n",
    "    wc_class_reports.append(_class_report)\n",
    "\n",
    "print(\"Accuracy exact: %.3f\" % (np.mean(wc_accuracy_scores)))\n",
    "print(\"Precision: %.3f\" % (np.mean(wc_precision_scores)))\n",
    "print(\"Recall: %.3f\" % (np.mean(wc_recall_scores)))\n",
    "print(\"F1 Score: %.3f\" % (np.mean(wc_f1_scores)))\n",
    "print(\"AUC: %.3f\\n\" % (np.mean(wc_auc_scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy exact: 0.858\n",
      "Precision: 0.859\n",
      "Recall: 0.857\n",
      "F1 Score: 0.858\n",
      "AUC: 0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BN  with GA\n",
    "from pomegranate import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df3 = pd.read_csv('datafiles/sample_featuresENTRbins.csv')\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)\n",
    "seed = 11\n",
    "\n",
    "wc_class_reports, wc_confmatrices, wc_auc_scores, wc_recall_scores, wc_precision_scores, wc_f1_scores, wc_accuracy_scores =[],[],[],[],[],[],[]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df3, df3['class'], test_size=0.3, random_state=42)\n",
    "\n",
    "count = 0\n",
    "xtrain = pd.read_csv('datafiles/train_dataset.csv')\n",
    "xtest = pd.read_csv('datafiles/test_dataset.csv')\n",
    "classval =  xtest['class']\n",
    "xtest['class']= np.nan\n",
    "trainarr = np.array(xtrain)\n",
    "testarr = np.array(xtest) \n",
    "tub = ((),(0,2,19,),(0,),(0,5,),(0,19,),(0,2,),(0,2,3,),(2,6,),(0,2,18,),(6,7,),(6,9,),(2,6,),(3,6,),(1,5,9,),(0,9,),(1,8,16,),(0,8,),(0,2,9,),(7,9,),(0,2,5,7,))\n",
    "model = BayesianNetwork.from_structure(xtrain,tub)\n",
    "model.fit(trainarr, n_jobs=-1)   \n",
    "   # xtest['class'] = np.nan\n",
    "wc_predicted = model.predict(testarr, n_jobs=-1)\n",
    "wc_predicted = np.array( wc_predicted, dtype = \"int64\")\n",
    "wc_predicted = wc_predicted[:,len(xtrain.columns)-1]\n",
    "wc_predicted = wc_predicted.reshape(-1)\n",
    "y_true = np.array(classval, dtype = \"int64\")\n",
    "y_true = y_true.reshape(-1)\n",
    "_precision, _recall, _fscore, _support = precision_recall_fscore_support(y_true, wc_predicted)\n",
    "_accuracy_score = accuracy_score(y_true, wc_predicted)\n",
    "_auc_score = roc_auc_score(y_true, wc_predicted)\n",
    "_conf_matrix = confusion_matrix(y_true, wc_predicted)\n",
    "_class_report = classification_report(y_true, wc_predicted)\n",
    "wc_accuracy_scores.append(_accuracy_score)\n",
    "wc_f1_scores.append(_fscore)\n",
    "wc_precision_scores.append(_precision)\n",
    "wc_recall_scores.append(_recall)\n",
    "wc_auc_scores.append(_auc_score)\n",
    "wc_confmatrices.append(_conf_matrix)\n",
    "wc_class_reports.append(_class_report)    \n",
    "    \n",
    "print(\"Accuracy exact: %.3f\" % (np.mean(wc_accuracy_scores)))\n",
    "print(\"Precision: %.3f\" % (np.mean(wc_precision_scores)))\n",
    "print(\"Recall: %.3f\" % (np.mean(wc_recall_scores)))\n",
    "print(\"F1 Score: %.3f\" % (np.mean(wc_f1_scores)))\n",
    "print(\"AUC: %.3f\\n\" % (np.mean(wc_auc_scores)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'genetic_feature_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-600669b698ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mclf_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mbest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenetic_feature_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_classification'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_best_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutation_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'genetic_feature_selection' is not defined"
     ]
    }
   ],
   "source": [
    "# All classifiers except BN\n",
    "from sklearn.model_selection import train_test_split\n",
    "df3 = pd.read_csv('datafiles/sample_featuresENTRbins.csv')\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)\n",
    "seed = 11\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False, random_state = seed)\n",
    "folds = []\n",
    "for train_index, test_index in kfold.split(df3,df3['class']):\n",
    "\n",
    "    xtrain = df3.loc[train_index,:]\n",
    "    xtest = df3.loc[test_index,:]\n",
    "    ytrain = xtrain['class']\n",
    "    ytest = xtest['class']\n",
    "    print(\"Logistic Regression\")\n",
    "    clf_lr = LogisticRegression(penalty = 'l2', random_state=0, solver='newton-cg',class_weight='balanced', n_jobs = -1)\n",
    "    best_features, best_scores = genetic_feature_selection(xtrain, ytrain, clf_lr, folds, task = 'binary_classification',eval_metric = 'auc', categorical_features = list(xtrain.columns) , n_classes = 2, sparse = False, iterations = 100, generation_size = 20, generation_best_ratio = 10, mutation_prob = 0.05, stopping_rounds = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Accuracy exact: 0.950\n",
      "Precision: 0.967\n",
      "Recall: 0.950\n",
      "F1 Score: 0.947\n",
      "AUC: 0.950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "#df3 = df2.reset_index(drop=True)\n",
    "df3 = pd.read_csv('datafiles/sample_featuresENTRbins.csv')\n",
    "np.random.seed(0)\n",
    "classval = df3['class']\n",
    "df3.drop(columns = 'class')\n",
    "#df = pd.read_csv('discretized_textual_features2.csv')\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False, random_state = seed)\n",
    "wc_class_reports, wc_confmatrices, wc_auc_scores, wc_recall_scores, wc_precision_scores, wc_f1_scores, wc_accuracy_scores =[],[],[],[],[],[],[]\n",
    "for train_index, test_index in kfold.split(df3,df3['class']):\n",
    "    xtrain = df3.loc[train_index,:]\n",
    "    xtest = df3.loc[test_index,:]   \n",
    "    trainarr = np.array(xtrain)\n",
    "    testarr = np.array(xtest)\n",
    "    ytest = classval.loc[test_index]\n",
    "    clf = LogisticRegression(penalty = 'l2', random_state=0, solver='newton-cg',class_weight='balanced', n_jobs = -1)\n",
    "    clf.fit(trainarr,xtrain['class'])\n",
    "\n",
    "    print(\"Inference process\\n\")\n",
    "    wc_predicted = clf.predict(testarr)\n",
    "    wc_predicted = np.array( wc_predicted, dtype = \"int64\")\n",
    "    print(wc_predicted.shape)\n",
    "    y_true = np.array(ytest, dtype = \"int64\")\n",
    "    print(y_true.shape)\n",
    "\n",
    "    print(\"Model Evaluation\")\n",
    "    _precision, _recall, _fscore, _support = precision_recall_fscore_support(y_true, wc_predicted)\n",
    "    _accuracy_score = balanced_accuracy_score(y_true, wc_predicted)\n",
    "    _auc_score = multiclass_roc_auc_score(y_true, wc_predicted)\n",
    "    _conf_matrix = confusion_matrix(y_true, wc_predicted)\n",
    "    _class_report = classification_report(y_true, wc_predicted)\n",
    "    wc_accuracy_scores.append(_accuracy_score)\n",
    "    wc_f1_scores.append(_fscore)\n",
    "    wc_precision_scores.append(_precision)\n",
    "    wc_recall_scores.append(_recall)\n",
    "    wc_auc_scores.append(_auc_score)\n",
    "    wc_confmatrices.append(_conf_matrix)\n",
    "    wc_class_reports.append(_class_report)\n",
    "    \n",
    "    \n",
    "print(\"Accuracy exact: %.3f\" % (np.mean(wc_accuracy_scores)))\n",
    "print(\"Precision: %.3f\" % (np.mean(wc_precision_scores)))\n",
    "print(\"Recall: %.3f\" % (np.mean(wc_recall_scores)))\n",
    "print(\"F1 Score: %.3f\" % (np.mean(wc_f1_scores)))\n",
    "print(\"AUC: %.3f\\n\" % (np.mean(wc_auc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Inference process\n",
      "\n",
      "(1000,)\n",
      "(1000,)\n",
      "Model Evaluation\n",
      "Accuracy exact: 0.921\n",
      "Precision: 0.924\n",
      "Recall: 0.921\n",
      "F1 Score: 0.920\n",
      "AUC: 0.921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "df3 = pd.read_csv('datafiles/sample_featuresENTRbins.csv')\n",
    "classval = df3['class']\n",
    "df3.drop(columns = 'class')\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False, random_state = seed)\n",
    "for train_index, test_index in kfold.split(df3,df3['class']):\n",
    "    xtrain = df3.loc[train_index,:]\n",
    "    xtest = df3.loc[test_index,:]   \n",
    "    trainarr = np.array(xtrain)\n",
    "    testarr = np.array(xtest)\n",
    "    ytest = classval.loc[test_index]\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "    clf.fit(trainarr,xtrain['class'])\n",
    "\n",
    "    print(\"Inference process\\n\")\n",
    "    wc_predicted = clf.predict(testarr)\n",
    "    wc_predicted = np.array( wc_predicted, dtype = \"int64\")\n",
    "    print(wc_predicted.shape)\n",
    "    y_true = np.array(ytest, dtype = \"int64\")\n",
    "    print(y_true.shape)\n",
    "\n",
    "    print(\"Model Evaluation\")\n",
    "    _precision, _recall, _fscore, _support = precision_recall_fscore_support(y_true, wc_predicted)\n",
    "    _accuracy_score = balanced_accuracy_score(y_true, wc_predicted)\n",
    "    _auc_score = multiclass_roc_auc_score(y_true, wc_predicted)\n",
    "    _conf_matrix = confusion_matrix(y_true, wc_predicted)\n",
    "    _class_report = classification_report(y_true, wc_predicted)\n",
    "    wc_accuracy_scores.append(_accuracy_score)\n",
    "    wc_f1_scores.append(_fscore)\n",
    "    wc_precision_scores.append(_precision)\n",
    "    wc_recall_scores.append(_recall)\n",
    "    wc_auc_scores.append(_auc_score)\n",
    "    wc_confmatrices.append(_conf_matrix)\n",
    "    wc_class_reports.append(_class_report)\n",
    "    \n",
    "    \n",
    "print(\"Accuracy exact: %.3f\" % (np.mean(wc_accuracy_scores)))\n",
    "print(\"Precision: %.3f\" % (np.mean(wc_precision_scores)))\n",
    "print(\"Recall: %.3f\" % (np.mean(wc_recall_scores)))\n",
    "print(\"F1 Score: %.3f\" % (np.mean(wc_f1_scores)))\n",
    "print(\"AUC: %.3f\\n\" % (np.mean(wc_auc_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "while(counter in range(1,5)):\n",
    "    counter = counter+1\n",
    "    print (counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
